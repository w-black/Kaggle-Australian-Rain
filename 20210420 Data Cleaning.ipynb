{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning\n",
    "I will use this notebook to clean the data set, trying to replace nulls in as many cases where it makes logical and mathematical sense. I will roll this into a 'clean_data' function so I can quickly clean the data rather than having to re run all the code chunks each time. I will then split the data into test and train csv files."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import os\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import datasets, linear_model\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas.api.types import is_string_dtype\n",
    "from pandas.api.types import is_numeric_dtype\n",
    "import scipy\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (20,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use external source to map location to latitude\n",
    "latdict = {\n",
    "    \"Adelaide\": \"-34.91490432431718\",\n",
    "    \"Albany\": \"-35.02474905886614\",\n",
    "    \"Albury\": \"-36.06534287815004\",\n",
    "    \"AliceSprings\": \"-23.69805670084839\",\n",
    "    \"BadgerysCreek\": \"-33.87695470721896\",\n",
    "    \"Ballarat\": \"-37.561716309375115\",\n",
    "    \"Bendigo\": \"-36.7554908916319\",\n",
    "    \"Brisbane\": \"-27.475717897882603\",\n",
    "    \"Cairns\": \"-16.92781685482217\",\n",
    "    \"Canberra\": \"-35.30773503404086\",\n",
    "    \"Cobar\": \"-31.504167276363866\",\n",
    "    \"CoffsHarbour\": \"-30.298002978449876\",\n",
    "    \"Dartmoor\": \"-37.925451468193096\",\n",
    "    \"Darwin\": \"-12.464083602807655\",\n",
    "    \"GoldCoast\": \"-28.014572596815473\",\n",
    "    \"Hobart\": \"-42.88435139189265\",\n",
    "    \"Katherine\": \"-14.456998531987214\",\n",
    "    \"Launceston\": \"-41.43266508391751\",\n",
    "    \"Melbourne\": \"-37.832462412802045\",\n",
    "    \"MelbourneAirport\": \"-37.66879996801125\",\n",
    "    \"Mildura\": \"-34.20248688142015\",\n",
    "    \"Moree\": \"-29.428569880868324\",\n",
    "    \"MountGambier\": \"-37.82374072116639\",\n",
    "    \"MountGinini\": \"-35.53217670083329\",\n",
    "    \"Newcastle\": \"-32.931643653584594\",\n",
    "    \"Nhil\": \"-36.322637084347\",\n",
    "    \"NorahHead\": \"-33.28147041348496\",\n",
    "    \"NorfolkIsland\": \"-29.034135426151366\",\n",
    "    \"Nuriootpa\": \"-34.468017870418535\",\n",
    "    \"PearceRAAF\": \"-31.667583781229556\",\n",
    "    \"Penrith\": \"-33.744842332442595\",\n",
    "    \"Perth\": \"-31.986585351851893\",\n",
    "    \"PerthAirport\": \"-31.93846563915158\",\n",
    "    \"Portland\": \"-38.34832717511207\",\n",
    "    \"Richmond\": \"-37.818604503111914\",\n",
    "    \"Sale\": \"-38.100948826120415\",\n",
    "    \"SalmonGums\": \"-32.842740170834155\",\n",
    "    \"Sydney\": \"-33.86371676520854\",\n",
    "    \"SydneyAirport\": \"-33.9421060860826\",\n",
    "    \"Townsville\": \"-19.264341792547878\",\n",
    "    \"Tuggeranong\": \"-35.46185196956041\",\n",
    "    \"Uluru\": \"-25.346664599700304\",\n",
    "    \"WaggaWagga\": \"-35.11756402381749\",\n",
    "    \"Walpole\": \"-34.966482092339895\",\n",
    "    \"Watsonia\": \"-37.70991777367249\",\n",
    "    \"Williamtown\": \"-37.86099076195903\",\n",
    "    \"Witchcliffe\": \"-34.030314070821824\",\n",
    "    \"Wollongong\": \"-34.43196249792971\",\n",
    "    \"Woomera\": \"-31.18123956846809\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use external source to map location to longitude\n",
    "longdict = {\n",
    "    \"Adelaide\": \"138.59602633990767\",\n",
    "    \"Albany\": \"117.88316237554488\",\n",
    "    \"Albury\": \"146.93525279045156\",\n",
    "    \"AliceSprings\": \"133.8787600142725\",\n",
    "    \"BadgerysCreek\": \"150.7484363529729\",\n",
    "    \"Ballarat\": \"143.84930592526567\",\n",
    "    \"Bendigo\": \"144.2801518461566\",\n",
    "    \"Brisbane\": \"153.02887201830356\",\n",
    "    \"Cairns\": \"145.7430348255027\",\n",
    "    \"Canberra\": \"149.1229092502184\",\n",
    "    \"Cobar\": \"145.83821542838913\",\n",
    "    \"CoffsHarbour\": \"153.12107860997904\",\n",
    "    \"Dartmoor\": \"141.27285789793294\",\n",
    "    \"Darwin\": \"130.84334958238955\",\n",
    "    \"GoldCoast\": \"153.40503715057645\",\n",
    "    \"Hobart\": \"147.3286420858417\",\n",
    "    \"Katherine\": \"132.26809234822562\",\n",
    "    \"Launceston\": \"147.1457335103628\",\n",
    "    \"Melbourne\": \"144.96053444028217\",\n",
    "    \"MelbourneAirport\": \"144.84076980637124\",\n",
    "    \"Mildura\": \"142.12879595976347\",\n",
    "    \"Moree\": \"149.7771468517488\",\n",
    "    \"MountGambier\": \"140.78081550124955\",\n",
    "    \"MountGinini\": \"148.77330846278252\",\n",
    "    \"Newcastle\": \"151.7590444755576\",\n",
    "    \"Nhil\": \"141.64167651316964\",\n",
    "    \"NorahHead\": \"151.57743077776965\",\n",
    "    \"NorfolkIsland\": \"167.9549498768209\",\n",
    "    \"Nuriootpa\": \"138.9928831519288\",\n",
    "    \"PearceRAAF\": \"116.02918925414023\",\n",
    "    \"Penrith\": \"150.68695749702303\",\n",
    "    \"Perth\": \"115.8515962142354\",\n",
    "    \"PerthAirport\": \"115.96748523272586\",\n",
    "    \"Portland\": \"141.60745855632877\",\n",
    "    \"Richmond\": \"145.00019734623154\",\n",
    "    \"Sale\": \"147.08029490271954\",\n",
    "    \"SalmonGums\": \"121.64337708357834\",\n",
    "    \"Sydney\": \"151.20782045617366\",\n",
    "    \"SydneyAirport\": \"151.1763664478918\",\n",
    "    \"Townsville\": \"146.81702724273325\",\n",
    "    \"Tuggeranong\": \"149.1116317085056\",\n",
    "    \"Uluru\": \"131.03645908713938\",\n",
    "    \"WaggaWagga\": \"147.3544221110696\",\n",
    "    \"Walpole\": \"116.75417748943707\",\n",
    "    \"Watsonia\": \"145.0859484467225\",\n",
    "    \"Williamtown\": \"144.89555627293157\",\n",
    "    \"Witchcliffe\": \"115.10127681861184\",\n",
    "    \"Wollongong\": \"150.88773768877098\",\n",
    "    \"Woomera\": \"136.81002833379935\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Initial Inspection and Column Additions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date                 0\n",
       "Location             0\n",
       "MinTemp           1087\n",
       "MaxTemp            882\n",
       "Rainfall          2607\n",
       "Evaporation      45945\n",
       "Sunshine         50109\n",
       "WindGustDir       8548\n",
       "WindGustSpeed     8485\n",
       "WindDir9am        8872\n",
       "WindDir3pm        2818\n",
       "WindSpeed9am      1568\n",
       "WindSpeed3pm      1764\n",
       "Humidity9am       2117\n",
       "Humidity3pm       2333\n",
       "Pressure9am      11876\n",
       "Pressure3pm      11842\n",
       "Cloud9am         43137\n",
       "Cloud3pm         44450\n",
       "Temp9am           1444\n",
       "Temp3pm           1620\n",
       "RainToday         2607\n",
       "RainTomorrow      2607\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the data from csv\n",
    "df = pd.read_csv(\"Kaggle Training Data.csv\")\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert dates to datetimes\n",
    "df['Date'] = pd.to_datetime(df['Date'], format=\"%d/%m/%Y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert location to lat/long and ensure it's float not object\n",
    "df['Latitude'] = df['Location'].map(latdict)\n",
    "df['Latitude'] = df['Latitude'].astype(float)\n",
    "\n",
    "df['Longitude'] = df['Location'].map(longdict)\n",
    "df['Longitude'] = df['Longitude'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add some other useful date values ( will one-hot encode these later on)\n",
    "df['Month_Num'] = pd.DatetimeIndex(df['Date']).month\n",
    "df['Year'] = pd.DatetimeIndex(df['Date']).year\n",
    "df['DayOfYear'] = pd.DatetimeIndex(df['Date']).dayofyear"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Using Linear Regression between two strongly correlated variables to fill missing cloud, sunshine and evaporation values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient = [[0.07100456]]\n",
      "Intercept = [0.7103748]\n",
      "Gradient = [[-0.50787855]]\n",
      "Intercept = [8.15432275]\n",
      "Gradient = [[0.65498279]]\n",
      "Intercept = [1.3981431]\n"
     ]
    }
   ],
   "source": [
    "# Linear Regression Models for extrapolating 'Cloud9am' from cloud, humidity and sunshine features\n",
    "\n",
    "# Extrapolating Cloud9am from Humidity 3pm\n",
    "x1 = df.dropna()[['Humidity3pm']].values\n",
    "y1 = df.dropna()[['Cloud9am']].values\n",
    "hum3_cloud9 = linear_model.LinearRegression()\n",
    "hum3_cloud9.fit(x1, y1)\n",
    "print('Gradient = ' + str(hum3_cloud9.coef_))\n",
    "print('Intercept = ' + str(hum3_cloud9.intercept_))\n",
    "\n",
    "# Extrapolating Cloud9am from Sunshine\n",
    "x7 = df.dropna()[['Sunshine']].values\n",
    "y7 = df.dropna()[['Cloud9am']].values\n",
    "sunshine_cloud9 = linear_model.LinearRegression()\n",
    "sunshine_cloud9.fit(x7, y7)\n",
    "print('Gradient = ' + str(sunshine_cloud9.coef_))\n",
    "print('Intercept = ' + str(sunshine_cloud9.intercept_))\n",
    "\n",
    "# Extrapolating Cloud9am from Cloud3\n",
    "x10 = df.dropna()[['Cloud3pm']].values\n",
    "y10 = df.dropna()[['Cloud9am']].values\n",
    "cloud3_cloud9 = linear_model.LinearRegression()\n",
    "cloud3_cloud9.fit(x10, y10)\n",
    "print('Gradient = ' + str(cloud3_cloud9.coef_))\n",
    "print('Intercept = ' + str(cloud3_cloud9.intercept_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient = [[0.06738554]]\n",
      "Intercept = [0.98621665]\n",
      "Gradient = [[0.05049076]]\n",
      "Intercept = [0.99754372]\n",
      "Gradient = [[-0.49414921]]\n",
      "Intercept = [8.14456851]\n",
      "Gradient = [[0.5848948]]\n",
      "Intercept = [1.85416821]\n"
     ]
    }
   ],
   "source": [
    "# Linear Regression Models for extrapolating 'Cloud3pm' from cloud, humidity and sunshine features\n",
    "\n",
    "# Extrapolating Cloud3pm from Humidity3pm\n",
    "x2 = df.dropna()[['Humidity3pm']].values\n",
    "y2 = df.dropna()[['Cloud3pm']].values\n",
    "hum3_cloud3 = linear_model.LinearRegression()\n",
    "hum3_cloud3.fit(x2, y2)\n",
    "print('Gradient = ' + str(hum3_cloud3.coef_))\n",
    "print('Intercept = ' + str(hum3_cloud3.intercept_))\n",
    "\n",
    "# Extrapolating Cloud3pm from Humidity9am\n",
    "x13 = df.dropna()[['Humidity9am']].values\n",
    "y13 = df.dropna()[['Cloud3pm']].values\n",
    "hum9_cloud3 = linear_model.LinearRegression()\n",
    "hum9_cloud3.fit(x13, y13)\n",
    "print('Gradient = ' + str(hum9_cloud3.coef_))\n",
    "print('Intercept = ' + str(hum9_cloud3.intercept_))\n",
    "\n",
    "# Extrapolating Cloud3pm from Sunshine\n",
    "x8 = df.dropna()[['Sunshine']].values\n",
    "y8 = df.dropna()[['Cloud3pm']].values\n",
    "sunshine_cloud3 = linear_model.LinearRegression()\n",
    "sunshine_cloud3.fit(x8, y8)\n",
    "print('Gradient = ' + str(sunshine_cloud3.coef_))\n",
    "print('Intercept = ' + str(sunshine_cloud3.intercept_))\n",
    "\n",
    "# Extrapolating Cloud3pm from Cloud9am\n",
    "x9 = df.dropna()[['Cloud9am']].values\n",
    "y9 = df.dropna()[['Cloud3pm']].values\n",
    "cloud9_cloud3 = linear_model.LinearRegression()\n",
    "cloud9_cloud3.fit(x9, y9)\n",
    "print('Gradient = ' + str(cloud9_cloud3.coef_))\n",
    "print('Intercept = ' + str(cloud9_cloud3.intercept_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient = [[-0.91186285]]\n",
      "Intercept = [11.57878106]\n",
      "Gradient = [[-0.99352747]]\n",
      "Intercept = [12.02020415]\n",
      "Gradient = [[-0.11671639]]\n",
      "Intercept = [13.5107794]\n",
      "Gradient = [[-0.10124569]]\n",
      "Intercept = [14.40179237]\n",
      "Gradient = [[0.26731699]]\n",
      "Intercept = [1.69084112]\n"
     ]
    }
   ],
   "source": [
    "# Linear Regression Models for extrapolating 'Sunshine' from cloud, humidty and temp features\n",
    "\n",
    "# Extrapolating Sunshine from Cloud9am\n",
    "x3 = df.dropna()[['Cloud9am']].values\n",
    "y3 = df.dropna()[['Sunshine']].values\n",
    "cloud9_sunshine = linear_model.LinearRegression()\n",
    "cloud9_sunshine.fit(x3, y3)\n",
    "print('Gradient = ' + str(cloud9_sunshine.coef_))\n",
    "print('Intercept = ' + str(cloud9_sunshine.intercept_))\n",
    "\n",
    "# Extrapolating Sunshine from Cloud3pm\n",
    "x4 = df.dropna()[['Cloud3pm']].values\n",
    "y4 = df.dropna()[['Sunshine']].values\n",
    "cloud3_sunshine = linear_model.LinearRegression()\n",
    "cloud3_sunshine.fit(x4, y4)\n",
    "print('Gradient = ' + str(cloud3_sunshine.coef_))\n",
    "print('Intercept = ' + str(cloud3_sunshine.intercept_))\n",
    "\n",
    "# Extrapolating Sunshine from Humidity3pm\n",
    "x5 = df.dropna()[['Humidity3pm']].values\n",
    "y5 = df.dropna()[['Sunshine']].values\n",
    "hum3_sunshine = linear_model.LinearRegression()\n",
    "hum3_sunshine.fit(x5, y5)\n",
    "print('Gradient = ' + str(hum3_sunshine.coef_))\n",
    "print('Intercept = ' + str(hum3_sunshine.intercept_))\n",
    "\n",
    "# Extrapolating Sunshine from Humidity9amm\n",
    "x11 = df.dropna()[['Humidity9am']].values\n",
    "y11 = df.dropna()[['Sunshine']].values\n",
    "hum9_sunshine = linear_model.LinearRegression()\n",
    "hum9_sunshine.fit(x11, y11)\n",
    "print('Gradient = ' + str(hum9_sunshine.coef_))\n",
    "print('Intercept = ' + str(hum9_sunshine.intercept_))\n",
    "\n",
    "# Extrapolating Sunshine from Temp3pm\n",
    "x12 = df.dropna()[['Temp3pm']].values\n",
    "y12 = df.dropna()[['Sunshine']].values\n",
    "temp3_sunshine = linear_model.LinearRegression()\n",
    "temp3_sunshine.fit(x12, y12)\n",
    "print('Gradient = ' + str(temp3_sunshine.coef_))\n",
    "print('Intercept = ' + str(temp3_sunshine.intercept_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient = [[0.34620242]]\n",
      "Intercept = [-2.91298131]\n"
     ]
    }
   ],
   "source": [
    "# Linear Regression Models for Extrapolating 'Evaporation' from 'Maxtemp'\n",
    "\n",
    "# Extrapolating Evaporation from MaxTemp\n",
    "x6 = df.dropna()[['MaxTemp']].values\n",
    "y6 = df.dropna()[['Evaporation']].values\n",
    "maxtemp_evap = linear_model.LinearRegression()\n",
    "maxtemp_evap.fit(x6, y6)\n",
    "print('Gradient = ' + str(maxtemp_evap.coef_))\n",
    "print('Intercept = ' + str(maxtemp_evap.intercept_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Entries = 116367\n",
      "Initial NaNs = 43137\n",
      "Remaining NaNs = 982\n"
     ]
    }
   ],
   "source": [
    "# Replaces 'Cloud9am' nulls with linearly regressed sunshine or cloud3pm of humidity3pm values \n",
    "cloud9am = np.array(df['Cloud9am']).reshape(-1, 1) \n",
    "sunshine = np.array(df['Sunshine']).reshape(-1, 1)\n",
    "cloud3pm = np.array(df['Cloud3pm']).reshape(-1, 1)\n",
    "humidity3pm = np.array(df['Humidity3pm']).reshape(-1, 1)\n",
    "for x in range(0, len(cloud9am)):\n",
    "    if np.isnan(cloud9am[x]):\n",
    "        if not np.isnan(sunshine[x]):\n",
    "            cloud9am[x] = sunshine_cloud9.predict(sunshine[x].reshape(-1,1))\n",
    "        else: \n",
    "            if not np.isnan(cloud3pm[x]):\n",
    "                cloud9am[x] = cloud3_cloud9.predict(cloud3pm[x].reshape(-1,1))\n",
    "            else:\n",
    "                if not np.isnan(humidity3pm[x]):\n",
    "                    cloud9am[x] = hum3_cloud9.predict(humidity3pm[x].reshape(-1,1))\n",
    "                      \n",
    "cloud9am_cleaned = cloud9am\n",
    "print('Total Entries = ' + str(len(cloud9am)))\n",
    "print('Initial NaNs = 43137')\n",
    "print('Remaining NaNs = ' + str(np.count_nonzero(np.isnan(cloud9am_cleaned))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Entries = 116367\n",
      "Initial NaNs = 44450\n",
      "Remaining NaNs = 982\n"
     ]
    }
   ],
   "source": [
    "# Replaces 'Cloud3pm' nulls with linearly regressed sunshine or cloud9am or humidity3pm values \n",
    "cloud9am = np.array(df['Cloud9am']).reshape(-1, 1) \n",
    "sunshine = np.array(df['Sunshine']).reshape(-1, 1)\n",
    "cloud3pm = np.array(df['Cloud3pm']).reshape(-1, 1)\n",
    "humidity3pm = np.array(df['Humidity3pm']).reshape(-1, 1)\n",
    "humidity9am = np.array(df['Humidity9am']).reshape(-1, 1)\n",
    "for x in range(0, len(cloud3pm)):\n",
    "    if np.isnan(cloud3pm[x]):\n",
    "        if not np.isnan(sunshine[x]):\n",
    "            cloud3pm[x] = sunshine_cloud3.predict(sunshine[x].reshape(-1,1))\n",
    "        else: \n",
    "            if not np.isnan(cloud9am[x]):\n",
    "                cloud3pm[x] = cloud9_cloud3.predict(cloud9am[x].reshape(-1,1))\n",
    "            else:\n",
    "                if not np.isnan(humidity3pm[x]):\n",
    "                    cloud3pm[x] = hum3_cloud3.predict(humidity3pm[x].reshape(-1,1))\n",
    "                else:\n",
    "                    if not np.isnan(humidity9am[x]):\n",
    "                        cloud9am[x] = hum9_cloud3.predict(humidity9am[x].reshape(-1,1))\n",
    "                        \n",
    "                    \n",
    "cloud3pm_cleaned = cloud3pm\n",
    "print('Total Entries = ' + str(len(cloud3pm)))\n",
    "print('Initial NaNs = 44450')\n",
    "print('Remaining NaNs = ' + str(np.count_nonzero(np.isnan(cloud3pm_cleaned))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Entries = 116367\n",
      "Initial NaNs = 50109\n",
      "Remaining NaNs = 419\n"
     ]
    }
   ],
   "source": [
    "# Replaces 'Sunshine' nulls with linearly regressed cloud3pm or cloud9am or humidity3pm or humidity9am values \n",
    "cloud9am = np.array(df['Cloud9am']).reshape(-1, 1) \n",
    "sunshine = np.array(df['Sunshine']).reshape(-1, 1)\n",
    "cloud3pm = np.array(df['Cloud3pm']).reshape(-1, 1)\n",
    "humidity3pm = np.array(df['Humidity3pm']).reshape(-1, 1)\n",
    "humidity9am = np.array(df['Humidity9am']).reshape(-1, 1)\n",
    "temp3pm = np.array(df['Temp3pm']).reshape(-1, 1)\n",
    "for x in range(0, len(sunshine)):\n",
    "    if np.isnan(sunshine[x]):\n",
    "        if not np.isnan(cloud3pm[x]):\n",
    "            sunshine[x] = cloud3_sunshine.predict(cloud3pm[x].reshape(-1,1))\n",
    "        else: \n",
    "            if not np.isnan(cloud9am[x]):\n",
    "                sunshine[x] = cloud9_sunshine.predict(cloud9am[x].reshape(-1,1))\n",
    "            else:\n",
    "                if not np.isnan(humidity3pm[x]):\n",
    "                    sunshine[x] = hum3_sunshine.predict(humidity3pm[x].reshape(-1,1))\n",
    "                else:\n",
    "                    if not np.isnan(humidity9am[x]):\n",
    "                        sunshine[x] = hum9_sunshine.predict(humidity9am[x].reshape(-1,1))\n",
    "                    else:\n",
    "                        if not np.isnan(temp3pm[x]):\n",
    "                            sunshine[x] = temp3_sunshine.predict(temp3pm[x].reshape(-1,1))\n",
    "                        \n",
    "sunshine_cleaned = sunshine\n",
    "print('Total Entries = ' + str(len(sunshine)))\n",
    "print('Initial NaNs = 50109')\n",
    "print('Remaining NaNs = ' + str(np.count_nonzero(np.isnan(sunshine_cleaned))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Entries = 116367\n",
      "Initial NaNs = 45945\n",
      "Remaining NaNs = 452\n"
     ]
    }
   ],
   "source": [
    "# Replaces 'Evaporation' Nulls with max temp\n",
    "evaporation = np.array(df['Evaporation']).reshape(-1, 1)\n",
    "maxtemp = np.array(df['MaxTemp']).reshape(-1, 1)\n",
    "for x in range(0, len(evaporation)):\n",
    "    if np.isnan(evaporation[x]):\n",
    "        if not np.isnan(maxtemp[x]):\n",
    "            evaporation[x] = maxtemp_evap.predict(maxtemp[x].reshape(-1,1))\n",
    "        \n",
    "evaporation_cleaned = evaporation\n",
    "print('Total Entries = ' + str(len(evaporation)))\n",
    "print('Initial NaNs = 45945')\n",
    "print('Remaining NaNs = ' + str(np.count_nonzero(np.isnan(evaporation_cleaned))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replaces columns in main df with cleaned versions\n",
    "df['Cloud9am'] = cloud9am_cleaned\n",
    "df['Cloud3pm'] = cloud3pm_cleaned\n",
    "df['Sunshine'] = sunshine_cleaned\n",
    "df['Evaporation'] = evaporation_cleaned"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Windspeed and Pressure donated from correlated locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-22-58fa7ae8644b>:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  windspeed_df['MaxSpeed'] = windspeed_df.max(axis=1)\n"
     ]
    }
   ],
   "source": [
    "# Take max of AM and PM for newwindgustspeed\n",
    "windspeed_df = df[['Date','Location','WindGustSpeed','WindSpeed9am','WindSpeed3pm']]\n",
    "windspeed_df['MaxSpeed'] = windspeed_df.max(axis=1)\n",
    "df['WindGustSpeed'] = windspeed_df['MaxSpeed']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy pressure values from defined correlated places\n",
    "new_pressure_df = df[['Date','Location','Pressure9am','Pressure3pm']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pairs of correlated destinations\n",
    "pairs = [['MountGinini','Canberra'],\n",
    "          ['Newcastle','Williamtown'],\n",
    "          ['Penrith','BadgerysCreek'],\n",
    "          ['SalmonGums','Walpole']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace missing pressure values from location pair\n",
    "collect_df = pd.DataFrame(columns=new_pressure_df.columns)\n",
    "\n",
    "for p in pairs:\n",
    "    # define missing/donor pressure pairs\n",
    "    df_missing = new_pressure_df[new_pressure_df['Location']==p[0]]\n",
    "    df_donor = new_pressure_df[new_pressure_df['Location']==p[1]]\n",
    "    df_missing.set_index(\"Date\", inplace=True)\n",
    "    df_donor.set_index(\"Date\", inplace=True)\n",
    "    \n",
    "    #replaces missing values with donor values\n",
    "    filled_df = df_missing.join(df_donor, rsuffix='_donor')\n",
    "    filled_df['Pressure3pm'] = filled_df['Pressure3pm_donor']\n",
    "    filled_df['Pressure9am'] = filled_df['Pressure9am_donor']\n",
    "    filled_df['Date'] = filled_df.index\n",
    "    filled_df.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    # save the new variables (they get overwritten)\n",
    "    collect_df = collect_df.append(filled_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge pressure values and fill gaps\n",
    "new_pressure_df = pd.merge(new_pressure_df, collect_df, on=['Date','Location'], how='left')\n",
    "new_pressure_df['Pressure9am'] = new_pressure_df['Pressure9am_x'].combine_first(new_pressure_df['Pressure9am_y'])\n",
    "new_pressure_df['Pressure3pm'] = new_pressure_df['Pressure3pm_x'].combine_first(new_pressure_df['Pressure3pm_y'])\n",
    "new_pressure_df = new_pressure_df[['Date','Location','Pressure9am','Pressure3pm']]\n",
    "\n",
    "#replace values in main df\n",
    "df['Pressure9am'] = new_pressure_df['Pressure9am']\n",
    "df['Pressure3pm'] = new_pressure_df['Pressure3pm']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Temperature Using min and max values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Adding new feature Min Temp\n",
    "#Filter to rows where MinTemp is not null and get average temps\n",
    "not_null_mintemp= df.loc[df['MinTemp'].notnull(), ('MinTemp', 'Location','Month_Num')]\n",
    "#Average temps\n",
    "mean_temperatures = not_null_mintemp.groupby (['Location', 'Month_Num']).agg(avg_min_temp = ('MinTemp', 'mean'))\n",
    "\n",
    "# Join onto original df\n",
    "min_temp_clean_df = pd.merge (df, mean_temperatures\n",
    "                                ,how='left'\n",
    "                                ,on=['Location','Month_Num'])\n",
    "\n",
    "# Create new test column coalescing original min temp with new one, if null\n",
    "df['MinTemp'] = min_temp_clean_df.MinTemp.combine_first(min_temp_clean_df.avg_min_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Adding new feature Max Temp\n",
    "#Filter to rows where MaxTemp is not null and get average temps\n",
    "not_null_maxtemp= df.loc[df['MaxTemp'].notnull(), ('MaxTemp', 'Location','Month_Num')]\n",
    "#Average temps\n",
    "mean_temperatures = not_null_maxtemp.groupby (['Location', 'Month_Num']).agg(avg_max_temp = ('MaxTemp', 'mean'))\n",
    "# Join onto original df\n",
    "max_temp_clean_df = pd.merge (df, mean_temperatures\n",
    "                                ,how='left'\n",
    "                                ,on=['Location','Month_Num'])\n",
    "# Create new test column coalescing original min temp with new one, if null\n",
    "df['MaxTemp'] = max_temp_clean_df.MaxTemp.combine_first(max_temp_clean_df.avg_max_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Cleaning Temp 3pm\n",
    "#Filter to rows where Temp3pm is not null and get average temps\n",
    "not_null_temp3pm = df.loc[df['Temp3pm'].notnull(), ('Temp3pm', 'Location','Month_Num')]\n",
    "#Average temps\n",
    "mean_temperatures = not_null_temp3pm.groupby (['Location', 'Month_Num']).agg(avg_temp3pm = ('Temp3pm', 'mean'))\n",
    "# Join onto original df\n",
    "temp3pm_clean_df = pd.merge (df, mean_temperatures\n",
    "                                ,how='left'\n",
    "                                ,on=['Location','Month_Num'])\n",
    "# Create new test column coalescing original min temp with new one, if null\n",
    "df['Temp3pm'] = temp3pm_clean_df.Temp3pm.combine_first(temp3pm_clean_df.avg_temp3pm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Cleaning Temp 9am\n",
    "#Filter to rows where Temp9pm is not null and get average temps\n",
    "not_null_temp9am = df.loc[df['Temp9am'].notnull(), ('Temp9am', 'Location','Month_Num')]\n",
    "#Average temps\n",
    "mean_temperatures = not_null_temp9am.groupby (['Location', 'Month_Num']).agg(avg_temp9am = ('Temp9am', 'mean'))\n",
    "# Join onto original df\n",
    "temp9am_clean_df = pd.merge (df, mean_temperatures\n",
    "                                ,how='left'\n",
    "                                ,on=['Location','Month_Num'])\n",
    "# Create new test column coalescing original min temp with new one, if null\n",
    "df['Temp9am'] = temp9am_clean_df.Temp9am.combine_first(temp9am_clean_df.avg_temp9am)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Replacing leftover columns with one month average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to take an individual column and replace nulls with month-location averages (or modes)\n",
    "def month_loc_avg(column, df):\n",
    "  #Filter to rows where columns is not null\n",
    "  not_null = df.loc[df[column].notnull(), (column, 'Location','Month_Num')]\n",
    "  \n",
    "  \n",
    "  if is_numeric_dtype(df[column]):\n",
    "    # Average values\n",
    "    means = not_null.groupby (['Location', 'Month_Num']).agg(avg_calc = (column, 'mean'))\n",
    "  else:\n",
    "    # Modal value\n",
    "    means = not_null.groupby (['Location', 'Month_Num']).agg(avg_calc = (column, lambda x: scipy.stats.mode(x, nan_policy='omit')[0]))\n",
    "  # Join onto original df\n",
    "  clean_df = pd.merge (df, means\n",
    "                                ,how='left'\n",
    "                                ,on=['Location','Month_Num'])\n",
    "  # replace column coalescing original values with new, if null\n",
    "  df[column] = clean_df[column].combine_first(clean_df['avg_calc'])\n",
    "  return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in df.columns:\n",
    "    if df[c].isnull().sum() > 0:\n",
    "      df = month_loc_avg(c, df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wind gust dir sometimes has entire months of nulls\n",
    "df['WindGustDir'] = df['WindGustDir'].combine_first(df['WindDir9am'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5 Creating Additional Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-36-cbf2186764ee>:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  rain_yday['DayOfYear'] = rain_yday['DayOfYear'] + 1 # won't work for days 365/366\n",
      "<ipython-input-36-cbf2186764ee>:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  rain_yday['RainYesterday'] = rain_yday['RainToday']\n",
      "C:\\Users\\wblack\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py:5168: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self[name] = value\n",
      "C:\\Users\\wblack\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:4163: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().drop(\n"
     ]
    }
   ],
   "source": [
    "# Create some features\n",
    "rain_yday = df[['Year','DayOfYear','Location','RainToday']]\n",
    "rain_yday['DayOfYear'] = rain_yday['DayOfYear'] + 1 # won't work for days 365/366\n",
    "rain_yday['RainYesterday'] = rain_yday['RainToday']\n",
    "fix_idx = rain_yday['DayOfYear'] > 365\n",
    "rain_yday[fix_idx].DayOfYear = 1\n",
    "rain_yday[fix_idx].Year = rain_yday[fix_idx].Year+1\n",
    "rain_yday.drop('RainToday', axis=1, inplace=True) \n",
    "df = pd.merge(df, rain_yday, how='left', on=['Location', 'Year','DayOfYear'])\n",
    "\n",
    "df['Humidity3pm_x_windspeed'] = df['Humidity3pm'] * df['WindGustSpeed']\n",
    "df['Sunshine_x_pressure3pm'] = df['Pressure3pm'] * df['Sunshine']\n",
    "df['HumidityChangeToday'] = df['Humidity3pm'] - df['Humidity9am']\n",
    "df['PressureChangeToday'] = df['Pressure3pm'] - df['Pressure9am']\n",
    "\n",
    "df['RainTodayBinary'] = df['RainToday'].replace({\"Yes\":1,\"No\":0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forward fill again - should only make minimal changes at this point\n",
    "df = df.ffill()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.6 Data Cleaning Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean data function wraps up al of the above into one function\n",
    "def clean_data(df):\n",
    "  get_predictor = False\n",
    "  y = 0\n",
    "  if 'RainTomorrow' in df.columns:\n",
    "    get_predictor = True\n",
    "    y = df.pop('RainTomorrow')\n",
    "\n",
    "  # Convert dates to datetimes\n",
    "  df['Date'] = pd.to_datetime(df['Date'], format=\"%d/%m/%Y\")\n",
    "  # Convert location to lat/long\n",
    "  df['Latitude'] = df['Location'].map(latdict)\n",
    "  df['Latitude'] = df['Latitude'].astype(float)\n",
    "\n",
    "  df['Longitude'] = df['Location'].map(longdict)\n",
    "  df['Longitude'] = df['Longitude'].astype(float)\n",
    "  # Add some other useful values\n",
    "  df['Month_Num'] = pd.DatetimeIndex(df['Date']).month\n",
    "  df['Year'] = pd.DatetimeIndex(df['Date']).year\n",
    "  df['DayOfYear'] = pd.DatetimeIndex(df['Date']).dayofyear\n",
    "\n",
    "\n",
    "  # Replaces 'Cloud9am' nulls with linearly regressed sunshine or cloud3pm of humidity3pm values \n",
    "  cloud9am = np.array(df['Cloud9am']).reshape(-1, 1) \n",
    "  sunshine = np.array(df['Sunshine']).reshape(-1, 1)\n",
    "  cloud3pm = np.array(df['Cloud3pm']).reshape(-1, 1)\n",
    "  humidity3pm = np.array(df['Humidity3pm']).reshape(-1, 1)\n",
    "  for x in range(0, len(cloud9am)):\n",
    "      if np.isnan(cloud9am[x]):\n",
    "          if not np.isnan(sunshine[x]):\n",
    "              cloud9am[x] = sunshine_cloud9.predict(sunshine[x].reshape(-1,1))\n",
    "          else: \n",
    "              if not np.isnan(cloud3pm[x]):\n",
    "                  cloud9am[x] = cloud3_cloud9.predict(cloud3pm[x].reshape(-1,1))\n",
    "              else:\n",
    "                  if not np.isnan(humidity3pm[x]):\n",
    "                      cloud9am[x] = hum3_cloud9.predict(humidity3pm[x].reshape(-1,1))\n",
    "                      \n",
    "  cloud9am_cleaned = cloud9am\n",
    "\n",
    "  # Replaces 'Cloud3pm' nulls with linearly regressed sunshine or cloud9am or humidity3pm values \n",
    "  cloud9am = np.array(df['Cloud9am']).reshape(-1, 1) \n",
    "  sunshine = np.array(df['Sunshine']).reshape(-1, 1)\n",
    "  cloud3pm = np.array(df['Cloud3pm']).reshape(-1, 1)\n",
    "  humidity3pm = np.array(df['Humidity3pm']).reshape(-1, 1)\n",
    "  humidity9am = np.array(df['Humidity9am']).reshape(-1, 1)\n",
    "  for x in range(0, len(cloud3pm)):\n",
    "      if np.isnan(cloud3pm[x]):\n",
    "          if not np.isnan(sunshine[x]):\n",
    "              cloud3pm[x] = sunshine_cloud3.predict(sunshine[x].reshape(-1,1))\n",
    "          else: \n",
    "              if not np.isnan(cloud9am[x]):\n",
    "                  cloud3pm[x] = cloud9_cloud3.predict(cloud9am[x].reshape(-1,1))\n",
    "              else:\n",
    "                  if not np.isnan(humidity3pm[x]):\n",
    "                      cloud3pm[x] = hum3_cloud3.predict(humidity3pm[x].reshape(-1,1))\n",
    "                  else:\n",
    "                      if not np.isnan(humidity9am[x]):\n",
    "                          cloud9am[x] = hum9_cloud3.predict(humidity9am[x].reshape(-1,1))\n",
    "                        \n",
    "                    \n",
    "  cloud3pm_cleaned = cloud3pm\n",
    "\n",
    "  # Replaces 'Sunshine' nulls with linearly regressed cloud3pm or cloud9am or humidity3pm or humidity9am values \n",
    "  cloud9am = np.array(df['Cloud9am']).reshape(-1, 1) \n",
    "  sunshine = np.array(df['Sunshine']).reshape(-1, 1)\n",
    "  cloud3pm = np.array(df['Cloud3pm']).reshape(-1, 1)\n",
    "  humidity3pm = np.array(df['Humidity3pm']).reshape(-1, 1)\n",
    "  humidity9am = np.array(df['Humidity9am']).reshape(-1, 1)\n",
    "  temp3pm = np.array(df['Temp3pm']).reshape(-1, 1)\n",
    "  for x in range(0, len(sunshine)):\n",
    "      if np.isnan(sunshine[x]):\n",
    "          if not np.isnan(cloud3pm[x]):\n",
    "              sunshine[x] = cloud3_sunshine.predict(cloud3pm[x].reshape(-1,1))\n",
    "          else: \n",
    "              if not np.isnan(cloud9am[x]):\n",
    "                  sunshine[x] = cloud9_sunshine.predict(cloud9am[x].reshape(-1,1))\n",
    "              else:\n",
    "                  if not np.isnan(humidity3pm[x]):\n",
    "                      sunshine[x] = hum3_sunshine.predict(humidity3pm[x].reshape(-1,1))\n",
    "                  else:\n",
    "                      if not np.isnan(humidity9am[x]):\n",
    "                          sunshine[x] = hum9_sunshine.predict(humidity9am[x].reshape(-1,1))\n",
    "                      else:\n",
    "                          if not np.isnan(temp3pm[x]):\n",
    "                              sunshine[x] = temp3_sunshine.predict(temp3pm[x].reshape(-1,1))\n",
    "                          \n",
    "  sunshine_cleaned = sunshine\n",
    "\n",
    "  # Replaces 'Evaporation' Nulls with max temp\n",
    "  evaporation = np.array(df['Evaporation']).reshape(-1, 1)\n",
    "  maxtemp = np.array(df['MaxTemp']).reshape(-1, 1)\n",
    "  for x in range(0, len(evaporation)):\n",
    "      if np.isnan(evaporation[x]):\n",
    "          if not np.isnan(maxtemp[x]):\n",
    "              evaporation[x] = maxtemp_evap.predict(maxtemp[x].reshape(-1,1))\n",
    "          \n",
    "  evaporation_cleaned = evaporation\n",
    "\n",
    "  df['Cloud9am'] = cloud9am_cleaned\n",
    "  df['Cloud3pm'] = cloud3pm_cleaned\n",
    "  df['Sunshine'] = sunshine_cleaned\n",
    "  df['Evaporation'] = evaporation_cleaned\n",
    "\n",
    "\n",
    "  # Take max of AM and PM for newwindgustspeed\n",
    "  windspeed_df = df[['Date','Location','WindGustSpeed','WindSpeed9am','WindSpeed3pm']]\n",
    "  windspeed_df['MaxSpeed'] = windspeed_df.max(axis=1)\n",
    "  df['WindGustSpeed'] = windspeed_df['MaxSpeed']\n",
    "  \n",
    "  # Copy pressure values from defined correlated places\n",
    "  new_pressure_df = df[['Date','Location','Pressure9am','Pressure3pm']]\n",
    "\n",
    "  pairs = [['MountGinini','Canberra'],\n",
    "          ['Newcastle','Williamtown'],\n",
    "          ['Penrith','BadgerysCreek'],\n",
    "          ['SalmonGums','Walpole']]\n",
    "\n",
    "  collect_df = pd.DataFrame(columns=new_pressure_df.columns)\n",
    "  for p in pairs:\n",
    "    df_missing = new_pressure_df[new_pressure_df['Location']==p[0]]\n",
    "    df_donor = new_pressure_df[new_pressure_df['Location']==p[1]]\n",
    "    df_missing.set_index(\"Date\", inplace=True)\n",
    "    df_donor.set_index(\"Date\", inplace=True)\n",
    "    filled_df = df_missing.join(df_donor, rsuffix='_donor')\n",
    "    filled_df['Pressure3pm'] = filled_df['Pressure3pm_donor']\n",
    "    filled_df['Pressure9am'] = filled_df['Pressure9am_donor']\n",
    "    filled_df['Date'] = filled_df.index\n",
    "    filled_df.reset_index(drop=True, inplace=True)\n",
    "    # save the new variables (they get overwritten)\n",
    "    collect_df = collect_df.append(filled_df)\n",
    "\n",
    "  new_pressure_df = pd.merge(new_pressure_df, collect_df, on=['Date','Location'], how='left')\n",
    "  new_pressure_df['Pressure9am'] = new_pressure_df['Pressure9am_x'].combine_first(new_pressure_df['Pressure9am_y'])\n",
    "  new_pressure_df['Pressure3pm'] = new_pressure_df['Pressure3pm_x'].combine_first(new_pressure_df['Pressure3pm_y'])\n",
    "  new_pressure_df = new_pressure_df[['Date','Location','Pressure9am','Pressure3pm']]\n",
    "  df['Pressure9am'] = new_pressure_df['Pressure9am']\n",
    "  df['Pressure3pm'] = new_pressure_df['Pressure3pm']\n",
    "\n",
    "  ## Min Temp\n",
    "  #Filter to rows where MinTemp is not null and get average temps\n",
    "  not_null_mintemp= df.loc[df['MinTemp'].notnull(), ('MinTemp', 'Location','Month_Num')]\n",
    "  #Average temps\n",
    "  mean_temperatures = not_null_mintemp.groupby (['Location', 'Month_Num']).agg(avg_min_temp = ('MinTemp', 'mean'))\n",
    "\n",
    "  # Join onto original df\n",
    "  min_temp_clean_df = pd.merge (df, mean_temperatures\n",
    "                                ,how='left'\n",
    "                                ,on=['Location','Month_Num'])\n",
    "\n",
    "  # Create new test column coalescing original min temp with new one, if null\n",
    "  df['MinTemp'] = min_temp_clean_df.MinTemp.combine_first(min_temp_clean_df.avg_min_temp)\n",
    "\n",
    "  ## Max Temp\n",
    "  #Filter to rows where MaxTemp is not null and get average temps\n",
    "  not_null_maxtemp= df.loc[df['MaxTemp'].notnull(), ('MaxTemp', 'Location','Month_Num')]\n",
    "  #Average temps\n",
    "  mean_temperatures = not_null_maxtemp.groupby (['Location', 'Month_Num']).agg(avg_max_temp = ('MaxTemp', 'mean'))\n",
    "  # Join onto original df\n",
    "  max_temp_clean_df = pd.merge (df, mean_temperatures\n",
    "                                ,how='left'\n",
    "                                ,on=['Location','Month_Num'])\n",
    "  # Create new test column coalescing original min temp with new one, if null\n",
    "  df['MaxTemp'] = max_temp_clean_df.MaxTemp.combine_first(max_temp_clean_df.avg_max_temp)\n",
    "\n",
    "  ## Temp 3pm\n",
    "  #Filter to rows where Temp3pm is not null and get average temps\n",
    "  not_null_temp3pm = df.loc[df['Temp3pm'].notnull(), ('Temp3pm', 'Location','Month_Num')]\n",
    "  #Average temps\n",
    "  mean_temperatures = not_null_temp3pm.groupby (['Location', 'Month_Num']).agg(avg_temp3pm = ('Temp3pm', 'mean'))\n",
    "  # Join onto original df\n",
    "  temp3pm_clean_df = pd.merge (df, mean_temperatures\n",
    "                                ,how='left'\n",
    "                                ,on=['Location','Month_Num'])\n",
    "  # Create new test column coalescing original min temp with new one, if null\n",
    "  df['Temp3pm'] = temp3pm_clean_df.Temp3pm.combine_first(temp3pm_clean_df.avg_temp3pm)\n",
    "\n",
    "  ## Temp 9am\n",
    "  #Filter to rows where Temp9pm is not null and get average temps\n",
    "  not_null_temp9am = df.loc[df['Temp9am'].notnull(), ('Temp9am', 'Location','Month_Num')]\n",
    "  #Average temps\n",
    "  mean_temperatures = not_null_temp9am.groupby (['Location', 'Month_Num']).agg(avg_temp9am = ('Temp9am', 'mean'))\n",
    "  # Join onto original df\n",
    "  temp9am_clean_df = pd.merge (df, mean_temperatures\n",
    "                                ,how='left'\n",
    "                                ,on=['Location','Month_Num'])\n",
    "  # Create new test column coalescing original min temp with new one, if null\n",
    "  df['Temp9am'] = temp9am_clean_df.Temp9am.combine_first(temp9am_clean_df.avg_temp9am)\n",
    "\n",
    "  # Fill gaps with month avg\n",
    "  for c in df.columns:\n",
    "    if df[c].isnull().sum() > 0:\n",
    "      df = month_loc_avg(c, df)\n",
    "\n",
    "  # Wind gust dir must have entire months of nulls\n",
    "  df['WindGustDir'] = df['WindGustDir'].combine_first(df['WindDir9am'])\n",
    "\n",
    "  # Create some features\n",
    "  rain_yday = df[['Year','DayOfYear','Location','RainToday']]\n",
    "  rain_yday['DayOfYear'] = rain_yday['DayOfYear'] + 1 # won't work for days 365/366\n",
    "  rain_yday['RainYesterday'] = rain_yday['RainToday']\n",
    "  fix_idx = rain_yday['DayOfYear'] > 365\n",
    "  rain_yday[fix_idx].DayOfYear = 1\n",
    "  rain_yday[fix_idx].Year = rain_yday[fix_idx].Year+1\n",
    "  rain_yday.drop('RainToday', axis=1, inplace=True) \n",
    "  df = pd.merge(df, rain_yday, how='left', on=['Location', 'Year','DayOfYear'])\n",
    "\n",
    "  df['Humidity3pm_x_windspeed'] = df['Humidity3pm'] * df['WindGustSpeed']\n",
    "  df['Sunshine_x_pressure3pm'] = df['Pressure3pm'] * df['Sunshine']\n",
    "  df['HumidityChangeToday'] = df['Humidity3pm'] - df['Humidity9am']\n",
    "  df['PressureChangeToday'] = df['Pressure3pm'] - df['Pressure9am']\n",
    "\n",
    "  df['RainTodayBinary'] = df['RainToday'].replace({\"Yes\":1,\"No\":0})\n",
    "\n",
    "  # Forward fill again - should only make minimal changes at this point\n",
    "  df = df.ffill()\n",
    "\n",
    "  if get_predictor:\n",
    "    df['RainTomorrow'] = y\n",
    "    df = df.bfill()\n",
    "  return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 Cleaning Data and Exporting Train Eval Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(116367, 23)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-41-e8050777f60a>:108: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  windspeed_df['MaxSpeed'] = windspeed_df.max(axis=1)\n",
      "<ipython-input-41-e8050777f60a>:200: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  rain_yday['DayOfYear'] = rain_yday['DayOfYear'] + 1 # won't work for days 365/366\n",
      "<ipython-input-41-e8050777f60a>:201: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  rain_yday['RainYesterday'] = rain_yday['RainToday']\n",
      "C:\\Users\\wblack\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py:5168: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self[name] = value\n",
      "C:\\Users\\wblack\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:4163: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().drop(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(116367, 34)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Date                       0\n",
       "Location                   0\n",
       "MinTemp                    0\n",
       "MaxTemp                    0\n",
       "Rainfall                   0\n",
       "Evaporation                0\n",
       "Sunshine                   0\n",
       "WindGustDir                0\n",
       "WindGustSpeed              0\n",
       "WindDir9am                 0\n",
       "WindDir3pm                 0\n",
       "WindSpeed9am               0\n",
       "WindSpeed3pm               0\n",
       "Humidity9am                0\n",
       "Humidity3pm                0\n",
       "Pressure9am                0\n",
       "Pressure3pm                0\n",
       "Cloud9am                   0\n",
       "Cloud3pm                   0\n",
       "Temp9am                    0\n",
       "Temp3pm                    0\n",
       "RainToday                  0\n",
       "Latitude                   0\n",
       "Longitude                  0\n",
       "Month_Num                  0\n",
       "Year                       0\n",
       "DayOfYear                  0\n",
       "RainYesterday              0\n",
       "Humidity3pm_x_windspeed    0\n",
       "Sunshine_x_pressure3pm     0\n",
       "HumidityChangeToday        0\n",
       "PressureChangeToday        0\n",
       "RainTodayBinary            0\n",
       "RainTomorrow               0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# loading train set and checking null count\n",
    "df = pd.read_csv(\"Kaggle Training Data.csv\")\n",
    "print(df.shape)\n",
    "df = clean_data(df)\n",
    "print(df.shape)\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(29093, 22)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-41-e8050777f60a>:108: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  windspeed_df['MaxSpeed'] = windspeed_df.max(axis=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(29093, 33)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-41-e8050777f60a>:200: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  rain_yday['DayOfYear'] = rain_yday['DayOfYear'] + 1 # won't work for days 365/366\n",
      "<ipython-input-41-e8050777f60a>:201: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  rain_yday['RainYesterday'] = rain_yday['RainToday']\n",
      "C:\\Users\\wblack\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py:5168: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self[name] = value\n",
      "C:\\Users\\wblack\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:4163: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().drop(\n"
     ]
    }
   ],
   "source": [
    "# loading test set and checking null count\n",
    "test_df = pd.read_csv(\"Kaggle Test Data.csv\")\n",
    "print(test_df.shape)\n",
    "df_test = clean_data(test_df)\n",
    "print(df_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data runs from  2007-11-01 00:00:00  to  2014-04-20 00:00:00 ,  2274  dates.\n",
      "Evaluation data runs from  2014-04-21 00:00:00  to  2015-11-10 00:00:00 ,  569  dates.\n"
     ]
    }
   ],
   "source": [
    "# Assign train/eval split - last 20% of data should be eval\n",
    "unique_dates = df['Date'].unique()\n",
    "cutoff = int(len(unique_dates)*0.8)\n",
    "train_dates = unique_dates[0:cutoff]\n",
    "df_train = df[df['Date'].isin(train_dates)]\n",
    "df_eval = df[~df['Date'].isin(train_dates)]\n",
    "\n",
    "print(f\"Train data runs from \", df_train[\"Date\"].min(), \" to \", df_train[\"Date\"].max(), \", \", len(df_train[\"Date\"].unique()), \" dates.\")\n",
    "print(f\"Evaluation data runs from \", df_eval[\"Date\"].min(), \" to \", df_eval[\"Date\"].max(), \", \", len(df_eval[\"Date\"].unique()), \" dates.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output csvs\n",
    "df_train.to_csv(\"TrainData.csv\")\n",
    "df_eval.to_csv(\"EvalData.csv\")\n",
    "df_test.to_csv(\"CleanedTestData.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
